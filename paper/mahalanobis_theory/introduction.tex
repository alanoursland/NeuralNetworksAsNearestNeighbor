\section{Introduction}

Neural networks have revolutionized machine learning, achieving remarkable success across diverse applications. Central to their efficacy is the use of activation functions, which introduce non-linearity and enable the modeling of complex relationships within data. While Rectified Linear Units (ReLU) have gained prominence due to their simplicity and effectiveness \citep{nair2010rectified}, the exploration of alternative activation functions remains an open and valuable area of research \citep{ramachandran2017searching}.

Neural network units are often viewed as linear separators that define decision boundaries between classes \citep{minsky1969perceptrons}, with larger activation values suggesting stronger contributions of features to those decisions. Our work challenges this perspective, exploring how individual neurons can be understood through the lens of statistical distance measures. Clustering techniques aim to minimize the distance between data points and feature prototypes, with smaller values indicating stronger membership to the feature or cluster \citep{macqueen1967methods}. Our work explores the intersection between these perspectives, leveraging the distance-minimization approach of clustering techniques to lay the groundwork for novel neural network designs based on statistical distance measures.

This paper establishes a novel connection between neural network architectures and the Mahalanobis distance, a statistical measure that accounts for the covariance structure of data \citep{mahalanobis1936generalized}. We present robust mathematical framework that bridges neural networks to this statistical distance measure and lay the groundwork for future research into neural network interpretability and design \citep{lipton2016mythos}. This distance-based interpretation has the potential to enhance model robustness, improve generalization, and offer more intuitive explanations of neural network decisions.

Our key contributions are:

\begin{enumerate}
    \item We establish a mathematical connection between neural network linear layers and the Mahalanobis distance, demonstrating how Absolute Value (Abs) activations facilitate distance-based interpretations.
    \item We analyze the implications of activation function choices on neural network behavior, comparing Abs and ReLU activations in terms of feature learning and training dynamics.
    \item We discuss the broader implications of this framework for neural network design and interpretability, laying the groundwork for more interpretable and stable models.
\end{enumerate}
